You have successfully learned how to tokenize text and represent it in a way that can be consumable by a model for the task you have specified. You will apply some of this knowledge to your project dataset that you have been working on so far.

Warning

**Manual Application**: In this project task, you will _manually_ apply the tokenization and text representation methods on your project dataset. You will learn and utilize the _automated_ preprocessing functionality that comes along with a pre-trained model in the later stages of the project work.

### Instructions

- In this assignment, you will be creating a model using your project dataset:
    - Choose between BoW and TF-IDF methods to represent your text.
    - As an added bonus, you may wish to explore the other method as well.
- Apply tokenization to the text in your dataset using the method you have chosen:
    
    - Consider removing punctuation, capitalization, and stop words if you have not already done so.
    
    Question
    
    How many documents are in your dataset? How many total words make up the vocabulary in your dataset?
    
- Build a model using any of the ML modules you have been introduced to that are appropriate for your dataset:
    
    - You can consider any of the models from scikit-learn (e.g., logistic regression, random forest, etc.), TensorFlow, PyTorch or Hugging Face.
- Test the performance of your model against some test data.
    
    Question
    
    **Reflection Questions**: How well does this model perform? What are some of the limitations you can see from this model you have created?
    

### Conclusion

You are most likely able to get some reasonable results from the model you have created so far. By now, you should have a sense that models can far exceed the performance you have achieved here. Be sure to save this model as you will be comparing the results with later models that you will build for your project submission using a fine-tuned model.