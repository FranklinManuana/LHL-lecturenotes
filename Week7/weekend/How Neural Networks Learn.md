
Instruction

Watch the video below to understand how weights in Neural Networks are optimized.

## Conclusion

We now have a basic idea of how to find the right weights. We've also heard about _Gradient Descent_ as a technique used in Neural Networks.

In the video we were shown that the algorithm to find the best possible combinations of these weights is called **Backpropagation**. It will be explained further in the following section.