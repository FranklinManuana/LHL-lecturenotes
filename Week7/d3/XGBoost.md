In the last section, we saw the most common ensemble techniques. We will now get to know the eXtreme Gradient Boosting (`XGBoost)` algorithm. It is a commonly used algorithm for predictive modeling across different industries.

## XGBoost

XGBoost (eXtreme Gradient Boosting) is a powerful machine learning algorithm that is widely used for solving classification and regression problems. It works by building an ensemble of decision trees and gradually improving their performance through a process called boosting. In boosting, the algorithm first builds a weak decision tree, which is then evaluated to identify the errors it makes. These errors are then used to build another decision tree that focuses on correcting those errors.

This process is repeated multiple times, with each subsequent tree focusing on correcting the errors made by the previous tree, until the performance of the ensemble is optimized. XGBoost is known for its speed, accuracy, and ability to handle large datasets. It has become one of the most popular machine learning algorithms in recent years, winning many Kaggle competitions and being used in a variety of real-world applications.

Instruction

Watch the video below to learn how _XGBoost_ works for regression problems.

Instruction

Watch the video below to learn how _XGBoost_ works for classification problems.

---

[

](https://web.compass.lighthouselabs.ca/p/ds-5/days/w07d3/activities/1927)