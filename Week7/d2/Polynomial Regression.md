So far we've studied _simple linear regression_. We will now take a look at **polynomial regression**, which enables us to model also non-linear relationships.

Multinomial regression is used when the response variable has more than two nominal categories and the independent variables may be continuous or categorical. In contrast, polynomial regression is a type of linear regression in which the relationship between the independent variable and the dependent variable is modeled as an nth degree polynomial.

Polynomial regression can be used with one or more independent variables, and involves fitting a polynomial function to the data. The polynomial function can include various transformations of the independent variable, such as squared or cubed terms, but it is not limited to a single feature.

## Reading

In polynomial regression, we can use different transformations of the variable x such as square, cube, square root, logarithmic or any other non-linear function to create additional features. By adding these transformed features to our linear regression model, we can account for non-linear relationships between the independent and dependent variables, which can result in a more accurate and flexible model.

y = bo x + b1x1 + b1x12 + ... + bnx1n

Instruction

Watch the following video for a brief explanation of _polynomial regression_ and why we still call it linear regression.